# ì˜¤í”„ë¼ì¸ í™˜ê²½ ì„¤ì • ê°€ì´ë“œ

ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

---

## ğŸ” ë¬¸ì œ ì¦ìƒ

```
Failed to resolve 'huggingface.co' ([Errno -3] Temporary failure in name resolution)
Max retries exceeded with url: /Qwen/Qwen3-VL-8B-Instruct/resolve/main/config.json
```

**ì›ì¸:**
- ë¡œì»¬ì— ëª¨ë¸ì´ ìˆìŒ
- í•˜ì§€ë§Œ Hugging Faceê°€ ì˜¨ë¼ì¸ìœ¼ë¡œ ìµœì‹  ë²„ì „ í™•ì¸ ì‹œë„
- ì˜¤í”„ë¼ì¸ í™˜ê²½ì´ë¼ ì‹¤íŒ¨

---

## âœ… í•´ê²° ë°©ë²•

### **ë°©ë²• 1: verifier.py ìˆ˜ì •** â­ (ì˜êµ¬ì )

**ìˆ˜ì • ìœ„ì¹˜:** `load_model()` ë©”ì„œë“œ

**Before:**
```python
self.model = AutoModelForVision2Seq.from_pretrained(
    model_id,
    cache_dir=str(self.cache_dir),
    trust_remote_code=True
)

self.processor = AutoProcessor.from_pretrained(
    model_id,
    cache_dir=str(self.cache_dir)
)
```

**After:**
```python
self.model = AutoModelForVision2Seq.from_pretrained(
    model_id,
    cache_dir=str(self.cache_dir),
    trust_remote_code=True,
    local_files_only=True  # â† ì¶”ê°€!
)

self.processor = AutoProcessor.from_pretrained(
    model_id,
    cache_dir=str(self.cache_dir),
    local_files_only=True  # â† ì¶”ê°€!
)
```

---

### **ë°©ë²• 2: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •** (ì„ì‹œ)

```bash
# ì‹¤í–‰ ì „ ì„¤ì •
export HF_HUB_OFFLINE=1
export TRANSFORMERS_OFFLINE=1

# ê·¸ ë‹¤ìŒ ì‹¤í–‰
bash run_multigpu_v2.sh
```

**ë©€í‹° GPU ìŠ¤í¬ë¦½íŠ¸ ìë™ ì„¤ì •:**

`run_multigpu_v2.sh`ì— ì´ë¯¸ í¬í•¨ë¨:
```python
# ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì„¤ì •
os.environ['HF_HUB_OFFLINE'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '1'
```

---

### **ë°©ë²• 3: ìˆ˜ë™ íŒ¨ì¹˜**

```bash
# verifier.py ë°±ì—…
cp verifier.py verifier.py.backup

# ìë™ íŒ¨ì¹˜
sed -i '/from_pretrained(/,/^[[:space:]]*)/s/)$/,\n                local_files_only=True\n            )/' verifier.py
```

---

## ğŸ”§ ì ìš© ë°©ë²•

### **Step 1: verifier.py ì—…ë°ì´íŠ¸**

```bash
# ë‹¤ìš´ë¡œë“œí•œ ìµœì‹  verifier.py ì‚¬ìš©
# ë˜ëŠ” ìˆ˜ë™ ìˆ˜ì •
```

**í™•ì¸:**
```bash
grep -A2 "from_pretrained" verifier.py | grep "local_files_only"
```

**ì¶œë ¥ì´ ì´ë ‡ê²Œ ë‚˜ì™€ì•¼ í•¨:**
```
                local_files_only=True  # ì˜¤í”„ë¼ì¸ ëª¨ë“œ ê°•ì œ
```

---

### **Step 2: í…ŒìŠ¤íŠ¸**

```bash
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì¶”ê°€ ë³´í—˜)
export HF_HUB_OFFLINE=1
export TRANSFORMERS_OFFLINE=1

# ì‹¤í–‰
bash run_multigpu_v2.sh
```

---

## ğŸ“‹ ëª¨ë¸ ìºì‹œ êµ¬ì¡° í™•ì¸

### **Hugging Face ìºì‹œ í˜•ì‹**

```
models/
â”œâ”€â”€ models--Qwen--Qwen3-VL-4B-Instruct/
â”‚   â”œâ”€â”€ blobs/
â”‚   â”‚   â””â”€â”€ (ëª¨ë¸ íŒŒì¼ë“¤)
â”‚   â”œâ”€â”€ refs/
â”‚   â”‚   â””â”€â”€ main
â”‚   â””â”€â”€ snapshots/
â”‚       â””â”€â”€ (í•´ì‹œ)/
â”‚           â”œâ”€â”€ config.json
â”‚           â”œâ”€â”€ model.safetensors
â”‚           â””â”€â”€ ...
â””â”€â”€ models--Qwen--Qwen3-VL-8B-Instruct/
    â””â”€â”€ ...
```

**í™•ì¸ ëª…ë ¹:**
```bash
ls -la models/models--Qwen--Qwen3-VL-8B-Instruct/snapshots/*/config.json
```

**ìˆìœ¼ë©´ âœ“** - ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì‚¬ìš© ê°€ëŠ¥

---

## ğŸš¨ ë¬¸ì œ í•´ê²°

### Q: ì—¬ì „íˆ ì˜¨ë¼ì¸ ì ‘ì† ì‹œë„

**í™•ì¸:**
```bash
grep "local_files_only" verifier.py
```

**ì—†ìœ¼ë©´:**
```bash
# verifier.pyê°€ ìµœì‹  ë²„ì „ì´ ì•„ë‹˜
# ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ìˆ˜ë™ ìˆ˜ì •
```

---

### Q: "config.json not found" ì—ëŸ¬

**ì›ì¸:** ëª¨ë¸ì´ ì™„ì „íˆ ë‹¤ìš´ë¡œë“œë˜ì§€ ì•ŠìŒ

**í•´ê²°:**
```bash
# 1. ëª¨ë¸ êµ¬ì¡° í™•ì¸
ls -la models/models--Qwen--Qwen3-VL-8B-Instruct/

# 2. snapshots í´ë” í™•ì¸
ls -la models/models--Qwen--Qwen3-VL-8B-Instruct/snapshots/

# 3. config.json ì°¾ê¸°
find models/ -name "config.json"

# 4. ì—†ìœ¼ë©´ ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ í•„ìš”
```

---

### Q: "model.safetensors not found" ì—ëŸ¬

**í™•ì¸:**
```bash
# ëª¨ë¸ íŒŒì¼ í™•ì¸
find models/models--Qwen--Qwen3-VL-8B-Instruct/ -name "*.safetensors"
```

**ìˆì–´ì•¼ í•˜ëŠ” íŒŒì¼ë“¤:**
```
model.safetensors
model-00001-of-00004.safetensors
model-00002-of-00004.safetensors
model-00003-of-00004.safetensors
model-00004-of-00004.safetensors
```

---

## ğŸ’¡ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì˜¨ë¼ì¸ í™˜ê²½)

ì˜¤í”„ë¼ì¸ìœ¼ë¡œ ê°€ê¸° ì „ì— ëª¨ë¸ì„ ì™„ì „íˆ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:

```bash
# ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ
python3 << EOF
from transformers import AutoModelForVision2Seq, AutoProcessor

model_id = "Qwen/Qwen3-VL-8B-Instruct"
cache_dir = "./models"

print("Downloading model...")
model = AutoModelForVision2Seq.from_pretrained(
    model_id,
    cache_dir=cache_dir,
    torch_dtype="auto"
)

print("Downloading processor...")
processor = AutoProcessor.from_pretrained(
    model_id,
    cache_dir=cache_dir
)

print("âœ“ Download complete!")
EOF
```

---

## ğŸ¯ ì „ì²´ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì˜¤í”„ë¼ì¸ í™˜ê²½ ì¤€ë¹„:

- [ ] ëª¨ë¸ ì™„ì „íˆ ë‹¤ìš´ë¡œë“œë¨
- [ ] `config.json` ì¡´ì¬ í™•ì¸
- [ ] `model.safetensors` ì¡´ì¬ í™•ì¸
- [ ] `verifier.py`ì— `local_files_only=True` ì¶”ê°€ë¨
- [ ] í™˜ê²½ ë³€ìˆ˜ `HF_HUB_OFFLINE=1` ì„¤ì •
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì„±ê³µ

---

## ğŸ“ ì‹¤í–‰ ì˜ˆì‹œ

### **ì˜¨ë¼ì¸ ì ‘ì† ì‹œë„ (Before)**
```
2025-12-11 09:10:09,780 - [GPU 0] WARNING - Failed to resolve 'huggingface.co'
Retrying in 1s [Retry 1/5]...
Retrying in 2s [Retry 2/5]...
(ê³„ì† ì¬ì‹œë„...)
```

### **ì˜¤í”„ë¼ì¸ ëª¨ë“œ (After)**
```
2025-12-11 09:15:30,123 - [GPU 0] INFO - Loading model: Qwen/Qwen3-VL-8B-Instruct
2025-12-11 09:15:30,124 - [GPU 0] INFO - Cache directory: ./models
2025-12-11 09:15:35,456 - [GPU 0] INFO - âœ“ Model loaded successfully
2025-12-11 09:15:35,457 - [GPU 0] INFO - GPU Memory - Allocated: 15.23GB
[GPU 0] Progress: 312/31227 (1.0%) | Speed: 4.2 img/s | ETA: 120.5 min
```

---

## ğŸ”— ì°¸ê³ 

**Hugging Face ì˜¤í”„ë¼ì¸ ë¬¸ì„œ:**
- https://huggingface.co/docs/transformers/installation#offline-mode

**í™˜ê²½ ë³€ìˆ˜:**
- `HF_HUB_OFFLINE=1` - Hugging Face Hub ì˜¤í”„ë¼ì¸ ëª¨ë“œ
- `TRANSFORMERS_OFFLINE=1` - Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤í”„ë¼ì¸ ëª¨ë“œ

---

**ì´ì œ ì™„ì „í•œ ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤!** ğŸ‰
